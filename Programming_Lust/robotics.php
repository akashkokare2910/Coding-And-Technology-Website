<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp"
    crossorigin="anonymous">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB"
    crossorigin="anonymous">
  <link rel="stylesheet" href="css/style.css">
  <title>Techblogs</title>
</head>

<body>
<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="index4.php">Programming Lust</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a href="index.php" class="nav-link">Consumer & Gadgets</a>
          </li>
          <li class="nav-item">
            <a href="about.php" class="nav-link">Mobile</a>
          </li>
          <li class="nav-item">
            <a href="automobile.php" class="nav-link">Automobile</a>
          </li>
          <li class="nav-item ">
            <a href="hardware.php" class="nav-link">Hardware</a>
          </li>
          <li class="nav-item active">
            <a href="robotics.php" class="nav-link">Robotics</a>
          </li>
          <li class="nav-item">
            <a href="softwares.php" class="nav-link">Software</a>
          </li>
          <li class="nav-item">
            <a href="latest.php" class="nav-link">Latest</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- PAGE HEADER -->
  <header id="page-header">
    <div class="container">
      <div class="row">
        <div class="col-md-6 m-auto text-center">
          <h1>Read Our Blog</h1>
          <p>Have a Taste of New Technologies around the world,which are truly worth viewing.</p>
        </div>
      </div>
    </div>
  </header>

  <!-- BLOG SECTION -->
  <section id="blog" class="py-3">
    <div class="container">
      <div class="row">
        <div class="col">
          <div class="card-columns">
            <div class="card">
              <img src="https://scx1.b-cdn.net/csz/news/800/2020/anobstacleav.jpg" alt="" class="img-fluid card-img-top">
              <div class="card-body">
                <h4 class="card-title">An obstacle avoidance system for flying robots inspired by owls
</h4>
                <small class="text-muted">Published by Programming Lust.</small>
                <hr>
                <p class="card-text">When developing robotic systems and computational tools, computer scientists often draw inspiration from animals or other biological systems.
                 Depending on a system's unique characteristics and purpose, in fact, nature typically offers specific examples of how it could achieve its goals rapidly and effectively.
Researchers at Shanghai Jiaotong University have recently developed a new bio-inspired and computer vision-based obstacle avoidance system that could improve the navigation of flying robots operating in dynamic environments.
 This system, presented in a paper pre-published on arXiv, is inspired by how owls detect and avoid objects or other animals in their surroundings.
 In the future, this system could be used to carry out missions in a wide range of environments, ranging from urban areas to natural environments largely populated by wildlife.
  The system could also inspire the development of other flying robots with enhanced obstacle avoidance capabilities based on similar designs. 
  In their next studies, the researchers will try to create systems that replicate the behavior of other animals, while also using reinforcement learning techniques to improve their system's sensing performance further.


                </p>
              </div>
            </div>

            

            <div class="card">
              <img src="https://scx1.b-cdn.net/csz/news/800/2020/anorigamiins.jpg" alt="" class="img-fluid card-img-top">
              <div class="card-body">
                <h4 class="card-title">An origami-inspired robotic fingertip with shape-morphing capabilities
</h4>
                <small class="text-muted">Published by Programming Lust.</small>
                <hr>
                <p class="card-text">To perform tasks that involve moving or handling objects, robots should swiftly adapt their grasp and manipulation strategies based on the properties of these objects and the environment surrounding them. 
                Most robotic hands developed so far, however, have a fixed and limiting structure; thus, they can perform a limited number of movements and can only grasp specific types of objects.
Researchers at Hong Kong University of Science and Technology have recently developed a robotic fingertip that can change its shape and switch across three different configurations, which could allow it to grasp a broader variety of objects. 
This fingertip's unique design, outlined in a paper presented at this year's IEEE International Conference on Automation Science and Engineering (CASE), is inspired by origami, the renowned Japanese art of paper folding.
The new origami-based shape morphing fingertiphas two main components: a soft origami skeleton that acts as the fingertip's morphing surface and motor-driven four-bar linkages that serve as actuation and transmission mechanisms.



                </p>
              </div>
            </div>

            

            <div class="card">
              <img src="https://scx1.b-cdn.net/csz/news/800/2020/arobotthatca.jpg" alt="" class="img-fluid card-img-top">
              <div class="card-body">
                <h4 class="card-title">A robot that can track specific people and follow them around</h4>
                <small class="text-muted">Published by Programming Lust.</small>
                <hr>
                <p class="card-text">Telling humans apart and following them as they move in their surrounding environment could be two highly valuable skills for service robots.
                 In fact, when combined, these two capabilities would allow robots to follow specific people as they are interacting with them or offering their assistance.
Researchers at Monash University, JDQ Systems and University of British Columbia recently developed a service robot designed to assist residents at elderly care homes or patients at other healthcare facilities. 
In a paper pre-published on arXiv, they presented a computational technique that allows their robot to identify and track people in its vicinity, following specific users as they are assisting them.
Scientists have developed face recognition tools, which allow robots to identify people but not follow their movements, and anonymous person tracking techniques, which allow robots to track a person's movements without knowing who they are.
 In order to follow specific people, however, a robot would need to simultaneously determine who they are and track their movements.


                </p>
              </div>
            </div>

            
          </div>
        </div>
      </div>
    </div>
  </section>

 
 <!-- Footer -->
 <footer class="page-footer font-small blue">

<!-- Copyright -->
<div class="footer-copyright text-center py-3">Â© 2020 Copyright:
  <a href="aboutus.php"> Programming Lust</a>
</div>
<!-- Copyright -->

</footer>
<!-- Footer -->


  <script src="http://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T"
    crossorigin="anonymous"></script>

  <script>
    // Get the current year for the copyright
    $('#year').text(new Date().getFullYear());


    

  </script>
</body>

</html>